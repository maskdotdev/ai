# AI Learning Path: From Fundamentals to Transformers

## Overview
This repository serves as a comprehensive learning path for understanding Artificial Intelligence from the ground up. It covers essential concepts starting from mathematical foundations to advanced deep learning architectures.

## Learning Path

### 1. Mathematical Foundations
- Linear Algebra
  - Vectors and Matrices
  - Eigenvalues and Eigenvectors
  - Matrix Operations
- Calculus
  - Derivatives and Gradients
  - Chain Rule
  - Backpropagation Basics
- Probability and Statistics
  - Probability Distributions
  - Statistical Inference
  - Bayesian Statistics

### 2. Machine Learning Basics
- Supervised Learning
- Unsupervised Learning
- Model Evaluation
- Feature Engineering
- Cross-Validation
- Regularization

### 3. Neural Networks
- Perceptrons
- Activation Functions
- Forward and Backward Propagation
- Optimization Algorithms
- Loss Functions
- Gradient Descent

### 4. Deep Learning
- Convolutional Neural Networks (CNNs)
- Recurrent Neural Networks (RNNs)
- Long Short-Term Memory (LSTM)
- Autoencoders
- Transfer Learning

### 5. Natural Language Processing
- Word Embeddings
- Sequence Models
- Attention Mechanism
- Transformers Architecture
- BERT and GPT Models

### 6. Advanced Topics
- Generative Models
- Reinforcement Learning
- Graph Neural Networks
- Self-Supervised Learning

## Resources
Each topic includes:
- Theoretical concepts
- Code implementations
- Practical exercises
- Real-world applications

## Prerequisites
- Basic Python programming
- Understanding of basic mathematics

## Getting Started
1. Clone this repository
2. Follow the learning path sequentially
3. Complete exercises in each section
4. Build practical projects

## Contributing
Feel free to contribute by:
- Adding new topics
- Improving explanations
- Fixing errors
- Sharing resources

## License
MIT License
